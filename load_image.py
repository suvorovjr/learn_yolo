import asyncio
import concurrent.futures
from pathlib import Path
from collections import defaultdict
import pandas as pd
import cv2
import numpy as np
import torch
from aiohttp import ClientSession
from ultralytics import YOLO

# –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
BASE_DIR: Path = Path(__file__).parent
RESULT_PATH: Path = BASE_DIR / "results/"
ANNOTATED_PATH = RESULT_PATH / "annotated/"

# –ö–æ–ª–æ–Ω–∫–∏
IMAGE_COLUMNS = [
    "–§–æ—Ç–æ –í—Ö–æ–¥–Ω–∞—è –≥—Ä—É–ø–ø–∞/—Ñ–∞—Å–∞–¥_–ú–§+Yota+–∫–æ–Ω–∫—É—Ä",
    "–§–æ—Ç–æ –†–µ—Å–µ–ø—à–Ω/–ó–æ–Ω–∞ –∫–∞—Å—Å_–ú–§+Yota+–∫–æ–Ω–∫—É—Ä",
    "–§–æ—Ç–æ –í–∏—Ç—Ä–∏–Ω—ã_–ú–§+Yota+–∫–æ–Ω–∫—É—Ä",
    "–§–æ—Ç–æ –ò–Ω—Ç–µ—Ä—å–µ—Ä_–ú–§+Yota+–∫–æ–Ω–∫—É—Ä",
]

EVALUATION_COLUMNS = [
    "–í—Ö–æ–¥–Ω–∞—è –∑–æ–Ω–∞ –ú–§",
    "–í—Ö–æ–¥–Ω–∞—è –∑–æ–Ω–∞ Yota",
    "–†–µ—Å–µ–ø—à–µ–Ω –ú–§",
    "–†–µ—Å–µ–ø—à–µ–Ω Yota",
    "–í–∏—Ç—Ä–∏–Ω—ã –ú–§",
    "–í–∏—Ç—Ä–∏–Ω—ã Yota",
    "–ò–Ω—Ç–µ—Ä—å–µ—Ä –ú–§",
    "–ò–Ω—Ç–µ—Ä—å–µ—Ä Yota",
]


### === 1. –†–∞–±–æ—Ç–∞ —Å —Ñ–∞–π–ª–∞–º–∏ === ###
def load_data(filename: str, sheet_name: str) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Excel."""
    print(f"üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ {filename} (–ª–∏—Å—Ç: {sheet_name})...")
    return pd.read_excel(filename, sheet_name=sheet_name)


def save_batch_to_excel(batch_df: pd.DataFrame, batch_num: int):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –±–∞—Ç—á –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª."""
    batch_filename = RESULT_PATH / f"batch_{batch_num}.xlsx"
    batch_df.to_excel(batch_filename, index=False)
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω –±–∞—Ç—á {batch_num} -> {batch_filename}")


def combine_batches():
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –±–∞—Ç—á–∏ –≤ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π Excel-—Ñ–∞–π–ª."""
    print("üîÑ –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –±–∞—Ç—á–∏ –≤ –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª...")
    all_batches = [pd.read_excel(f) for f in RESULT_PATH.glob("batch_*.xlsx")]
    final_df = pd.concat(all_batches, ignore_index=True)
    final_df.to_excel("final_output.xlsx", index=False)
    print("‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫ final_output.xlsx")


### === 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π === ###
async def load_resized_image(
    session: ClientSession, url: str, sem: asyncio.Semaphore
) -> np.ndarray:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∏–∑–º–µ–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    async with sem:
        async with session.get(url) as response:
            if response.status != 200:
                raise ValueError(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {response.status}")
            image_bytes = await response.read()
            image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                raise ValueError(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {url}")
            return image


async def load_images_in_batch(batch_df: pd.DataFrame) -> dict:
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –±–∞—Ç—á–µ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö —Å–≤—è–∑—å —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏."""
    print("üì∏ –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –±–∞—Ç—á–∞...")
    semaphore = asyncio.Semaphore(10)
    async with ClientSession() as session:
        tasks = {
            (idx, img_col): asyncio.create_task(
                load_resized_image(session, row[img_col], semaphore)
            )
            for idx, row in batch_df.iterrows()
            for img_col in IMAGE_COLUMNS
            if row[img_col] != "-"
        }

        images = {}
        for key, task in tasks.items():
            try:
                images[key] = await task
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {key}: {e}")
                images[key] = None

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        return images


def detect_objects_for_batch(model_path: str, images: list[np.ndarray]) -> list[dict]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–∞—Ç—á –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ."""
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = YOLO(model_path)
    model.to(device)

    detections = model.predict(images, verbose=False)
    objects_info_list = []

    for i, result in enumerate(detections):
        objects_info = defaultdict(int)
        for box, cls in zip(result.boxes.xyxy, result.boxes.cls):
            label = model.names[int(cls)]
            x1, y1, x2, y2 = map(int, box)
            area_px = (x2 - x1) * (y2 - y1)
            objects_info[label] += area_px
        objects_info_list.append(objects_info)
    return objects_info_list


async def detect_objects_in_batch(model_path: str, images: dict) -> dict:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –±–∞—Ç—á–µ —Å –ø–æ–º–æ—â—å—é YOLO –≤ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö."""
    print("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º YOLO-–æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö...")
    loop = asyncio.get_running_loop()

    batch_size = 8
    image_batches = [
        list(images.values())[i : i + batch_size]
        for i in range(0, len(images), batch_size)
    ]

    with concurrent.futures.ProcessPoolExecutor(max_workers=4) as executor:
        tasks = [
            loop.run_in_executor(executor, detect_objects_for_batch, model_path, batch)
            for batch in image_batches
        ]
        results = await asyncio.gather(*tasks)

    detections = {}
    image_keys = list(images.keys())
    for i, batch_results in enumerate(results):
        for j, objects_info in enumerate(batch_results):
            detections[image_keys[i * batch_size + j]] = objects_info

    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(detections)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ YOLO")
    return detections


def process_detections(batch_df: pd.DataFrame, detections: dict):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—Ü–µ–Ω–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏."""
    print("üìù –ü—Ä–∏–º–µ–Ω—è–µ–º –æ—Ü–µ–Ω–∫–∏ –∫ –±–∞—Ç—á—É...")
    for (idx, img_col), objects_info in detections.items():
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –ú–§ –∏ Yota
        eval_col_mf = EVALUATION_COLUMNS[IMAGE_COLUMNS.index(img_col) * 2]  # –ú–§
        eval_col_yota = EVALUATION_COLUMNS[IMAGE_COLUMNS.index(img_col) * 2 + 1]  # Yota

        batch_df.at[idx, eval_col_mf] = get_mark(objects_info, "Megafon")
        batch_df.at[idx, eval_col_yota] = get_mark(objects_info, "Yota")

    print("‚úÖ –û—Ü–µ–Ω–∫–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è")


def get_mark(objects_info, operator: str) -> int:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–±—ä–µ–∫—Ç—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ü–µ–Ω–∫—É –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ —Å–≤—è–∑–∏."""
    other_operators = {"Bilain", "T2", "MTC"}
    operator_area = objects_info.get(operator, 0)
    other_areas = [objects_info.get(op, 0) for op in other_operators]

    if 0 < operator_area < 25_000:
        pixels = 2500
    elif 25_000 <= operator_area < 100_000:
        pixels = 5000
    else:
        pixels = 7500
        

    if any(area > operator_area + pixels for area in other_areas if area != 0):
        return 0

    if any(
        operator_area - pixels <= area <= operator_area + pixels
        for area in other_areas
        if area != 0
    ):
        return 1

    if operator_area == 0:
        return 0 if any(other_areas) else 1

    return 2


### === 3. –û—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å === ###
async def process_batch(batch_df: pd.DataFrame, batch_num: int):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –±–∞—Ç—á."""
    print(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –±–∞—Ç—á–∞ {batch_num}...")
    images = await load_images_in_batch(batch_df)
    detections = await detect_objects_in_batch("best.pt", images)
    process_detections(batch_df, detections)
    save_batch_to_excel(batch_df, batch_num)


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    df = load_data("test_file.xlsx", "–ì–¥–µ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å")
    RESULT_PATH.mkdir(parents=True, exist_ok=True)
    ANNOTATED_PATH.mkdir(parents=True, exist_ok=True)

    batch_size = 100
    total_batches = (len(df) + batch_size - 1) // batch_size  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π

    for batch_num, start in enumerate(range(0, len(df), batch_size), start=1):
        print(f"\nüöÄ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á {batch_num}/{total_batches}...")

        batch_df = df.iloc[start: start + batch_size].copy()
        await process_batch(batch_df, batch_num) 
    combine_batches()


if __name__ == "__main__":
    asyncio.run(main())
